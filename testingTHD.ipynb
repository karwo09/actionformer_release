{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'thumos_AVF', 'train_split': ['validation'], 'val_split': ['test'], 'dataset': {'json_file': './data/thumos/annotations/thumos14.json', 'feat_folder': './data/thumos/i3d_features', 'file_prefix': None, 'file_ext': '.npy', 'num_classes': 20, 'input_dim': 2048, 'feat_stride': 4, 'num_frames': 16, 'trunc_thresh': 0.5, 'crop_ratio': [0.9, 1.0], 'max_seq_len': 2304, 'default_fps': None, 'downsample_rate': 1, 'force_upsampling': False}, 'model': {'fpn_type': 'identity', 'max_buffer_len_factor': 6.0, 'n_mha_win_size': 19, 'backbone_type': 'AVFusionConvTransformer', 'backbone_arch': (2, 2, 5, 2, 2), 'scale_factor': 2, 'regression_range': [(0, 4), (4, 8), (8, 16), (16, 32), (32, 64), (64, 10000)], 'n_head': 4, 'embd_kernel_size': 3, 'embd_dim': 512, 'embd_with_ln': True, 'fpn_dim': 512, 'fpn_with_ln': True, 'fpn_start_level': 0, 'head_dim': 512, 'head_kernel_size': 3, 'head_num_layers': 3, 'head_with_ln': True, 'use_abs_pe': False, 'use_rel_pe': False, 'input_dim': 2048, 'num_classes': 20, 'max_seq_len': 2304, 'train_cfg': {'init_loss_norm': 100, 'clip_grad_l2norm': 1.0, 'cls_prior_prob': 0.01, 'center_sample': 'radius', 'center_sample_radius': 1.5, 'use_text': False, 'use_audio': True, 'aformer_path': '/home/karolwojtulewicz/code/actionformer_release/pretrained/thumos_i3d_reproduce/epoch_034.pth.tar', 'freeze_aformer': True, 'loss_weight': 1.0, 'head_empty_cls': [], 'dropout': 0.0, 'droppath': 0.1, 'label_smoothing': 0.0}, 'test_cfg': {'voting_thresh': 0.7, 'pre_nms_topk': 2000, 'max_seg_num': 200, 'min_score': 0.001, 'multiclass_nms': True, 'pre_nms_thresh': 0.001, 'iou_threshold': 0.1, 'nms_method': 'soft', 'nms_sigma': 0.5, 'duration_thresh': 0.05, 'ext_score_file': None}}, 'opt': {'learning_rate': 0.0001, 'epochs': 75, 'weight_decay': 0.01, 'type': 'AdamW', 'momentum': 0.9, 'warmup': True, 'warmup_epochs': 5, 'schedule_type': 'cosine', 'schedule_steps': [], 'schedule_gamma': 0.1}, 'loader': {'batch_size': 2, 'num_workers': 4}, 'train_cfg': {'init_loss_norm': 100, 'clip_grad_l2norm': 1.0, 'cls_prior_prob': 0.01, 'center_sample': 'radius', 'center_sample_radius': 1.5, 'use_text': False, 'use_audio': True, 'aformer_path': '/home/karolwojtulewicz/code/actionformer_release/pretrained/thumos_i3d_reproduce/epoch_034.pth.tar', 'freeze_aformer': True, 'loss_weight': 1.0, 'head_empty_cls': [], 'dropout': 0.0, 'droppath': 0.1, 'label_smoothing': 0.0}, 'test_cfg': {'voting_thresh': 0.7, 'pre_nms_topk': 2000, 'max_seg_num': 200, 'min_score': 0.001, 'multiclass_nms': True, 'pre_nms_thresh': 0.001, 'iou_threshold': 0.1, 'nms_method': 'soft', 'nms_sigma': 0.5, 'duration_thresh': 0.05, 'ext_score_file': None}, 'output_folder': './ckpt/', 'init_rand_seed': 1234567891, 'devices': ['cuda:0'], 'model_name': 'LocPointTransformer'}\n",
      "Loading pretrained af model...\n",
      "Could not load pretrained af model\n",
      "\n",
      "=> loading checkpoint './ckpt/thumos_i3d_VGGish_AVF_reproduce/epoch_025.pth.tar'\n",
      "Loading from EMA model ...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from libs.core.config import load_config\n",
    "import os\n",
    "from libs.datasets.datasets import make_data_loader, make_dataset\n",
    "from libs.modeling.models import make_meta_arch\n",
    "\n",
    "from libs.utils.train_utils import fix_random_seed\n",
    "\"\"\"0. load config\"\"\"\n",
    "    # sanity check\n",
    "    \n",
    "class Args:\n",
    "    ckpt = \"./ckpt/thumos_i3d_VGGish_AVF_reproduce\"\n",
    "    config = \"./configs/thumos_i3d_VGGish_AVF.yaml\"\n",
    "    epoch = -1\n",
    "    topk = -1\n",
    "    saveonly = False\n",
    "    print_freq = 10\n",
    "args = Args()\n",
    "\n",
    "\n",
    "if os.path.isfile(args.config):\n",
    "        cfg = load_config(args.config)\n",
    "else:\n",
    "    raise ValueError(\"Config file does not exist.\")\n",
    "assert len(cfg['val_split']) > 0, \"Test set must be specified!\"\n",
    "if \".pth.tar\" in args.ckpt:\n",
    "    assert os.path.isfile(args.ckpt), \"CKPT file does not exist!\"\n",
    "    ckpt_file = args.ckpt\n",
    "else:\n",
    "    assert os.path.isdir(args.ckpt), \"CKPT file folder does not exist!\"\n",
    "    if args.epoch > 0:\n",
    "        ckpt_file = os.path.join(\n",
    "            args.ckpt, 'epoch_{:03d}.pth.tar'.format(args.epoch)\n",
    "        )\n",
    "    else:\n",
    "        ckpt_file_list = sorted(glob.glob(os.path.join(args.ckpt, '*.pth.tar')))\n",
    "        ckpt_file = ckpt_file_list[-1]\n",
    "    assert os.path.exists(ckpt_file)\n",
    "\n",
    "if args.topk > 0:\n",
    "    cfg['model']['test_cfg']['max_seg_num'] = args.topk\n",
    "print(str(cfg))\n",
    "\n",
    "\"\"\"1. fix all randomness\"\"\"\n",
    "# fix the random seeds (this will fix everything)\n",
    "_ = fix_random_seed(0, include_cuda=True)\n",
    "\n",
    "\"\"\"2. create dataset / dataloader\"\"\"\n",
    "val_dataset = make_dataset(\n",
    "    cfg['dataset_name'], False, cfg['val_split'], **cfg['dataset']\n",
    ")\n",
    "# set bs = 1, and disable shuffle\n",
    "val_loader = make_data_loader(\n",
    "    val_dataset, False, None, 1, cfg['loader']['num_workers']\n",
    ")\n",
    "\n",
    "\"\"\"3. create model and evaluator\"\"\"\n",
    "# model\n",
    "model = make_meta_arch(cfg['model_name'], **cfg['model'])\n",
    "\n",
    "\"\"\"4. load ckpt\"\"\"\n",
    "print(\"=> loading checkpoint '{}'\".format(ckpt_file))\n",
    "# load ckpt, reset epoch / best rmse\n",
    "checkpoint = torch.load(\n",
    "    ckpt_file,\n",
    "    map_location = lambda storage, loc: storage.cuda(cfg['devices'][0])\n",
    ")\n",
    "\n",
    "\n",
    "# out = model(val_dataset[0])\n",
    "# make_dot(out).render(\"rnn_torchviz\", format=\"png\")\n",
    "\n",
    "# load ema model instead\n",
    "print(\"Loading from EMA model ...\")\n",
    "try:\n",
    "    model.load_state_dict(checkpoint['state_dict_ema'])\n",
    "except:\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    \n",
    "del checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PtTransformer(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (backbone): AVFusionConvTransformerBackbone(\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (video_stem): ConvTransformerBackbone_StemOnly(\n",
      "      (model): PtTransformer(\n",
      "        (sigmoid): Sigmoid()\n",
      "        (backbone): ConvTransformerBackbone_Orig(\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (embd): ModuleList(\n",
      "            (0): MaskedConv1D(\n",
      "              (conv): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "            (1): MaskedConv1D(\n",
      "              (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (embd_norm): ModuleList(\n",
      "            (0): LayerNorm()\n",
      "            (1): LayerNorm()\n",
      "          )\n",
      "          (stem): ModuleList(\n",
      "            (0): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): Identity()\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "            (1): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): Identity()\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "          )\n",
      "          (branch): ModuleList(\n",
      "            (0): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "            (1): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "            (2): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "            (3): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "            (4): TransformerBlock(\n",
      "              (ln1): LayerNorm()\n",
      "              (ln2): LayerNorm()\n",
      "              (attn): LocalMaskedMHCA(\n",
      "                (query_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (query_norm): LayerNorm()\n",
      "                (key_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (key_norm): LayerNorm()\n",
      "                (value_conv): MaskedConv1D(\n",
      "                  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "                )\n",
      "                (value_norm): LayerNorm()\n",
      "                (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "              (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (mlp): Sequential(\n",
      "                (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Dropout(p=0.0, inplace=True)\n",
      "                (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "                (4): Dropout(p=0.0, inplace=True)\n",
      "              )\n",
      "              (drop_path_attn): AffineDropPath()\n",
      "              (drop_path_mlp): AffineDropPath()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (neck): FPNIdentity(\n",
      "          (fpn_norms): ModuleList(\n",
      "            (0): LayerNorm()\n",
      "            (1): LayerNorm()\n",
      "            (2): LayerNorm()\n",
      "            (3): LayerNorm()\n",
      "            (4): LayerNorm()\n",
      "            (5): LayerNorm()\n",
      "          )\n",
      "        )\n",
      "        (point_generator): PointGenerator(\n",
      "          (buffer_points): BufferList()\n",
      "        )\n",
      "        (cls_head): PtTransformerClsHead(\n",
      "          (act): ReLU()\n",
      "          (head): ModuleList(\n",
      "            (0): MaskedConv1D(\n",
      "              (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "            (1): MaskedConv1D(\n",
      "              (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): ModuleList(\n",
      "            (0): LayerNorm()\n",
      "            (1): LayerNorm()\n",
      "          )\n",
      "          (cls_head): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "        (reg_head): PtTransformerRegHead(\n",
      "          (act): ReLU()\n",
      "          (head): ModuleList(\n",
      "            (0): MaskedConv1D(\n",
      "              (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "            (1): MaskedConv1D(\n",
      "              (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): ModuleList(\n",
      "            (0): LayerNorm()\n",
      "            (1): LayerNorm()\n",
      "          )\n",
      "          (scale): ModuleList(\n",
      "            (0): Scale()\n",
      "            (1): Scale()\n",
      "            (2): Scale()\n",
      "            (3): Scale()\n",
      "            (4): Scale()\n",
      "            (5): Scale()\n",
      "          )\n",
      "          (offset_head): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stem_audio): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): Identity()\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): Identity()\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "    )\n",
      "    (bottle_neck): BottleNeckAudioVideoRMAttn(\n",
      "      (linear_down_v1): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (linear_down_a1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (linear_down_v2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (linear_down_a2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (linear_out): Linear(in_features=128, out_features=512, bias=True)\n",
      "    )\n",
      "    (branch): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "      (3): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "      (4): TransformerBlock(\n",
      "        (ln1): LayerNorm()\n",
      "        (ln2): LayerNorm()\n",
      "        (attn): LocalMaskedMHCA(\n",
      "          (query_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (query_norm): LayerNorm()\n",
      "          (key_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (key_norm): LayerNorm()\n",
      "          (value_conv): MaskedConv1D(\n",
      "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), groups=512, bias=False)\n",
      "          )\n",
      "          (value_norm): LayerNorm()\n",
      "          (key): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (query): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (value): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (pool_skip): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (mlp): Sequential(\n",
      "          (0): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=True)\n",
      "          (3): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (drop_path_attn): AffineDropPath()\n",
      "        (drop_path_mlp): AffineDropPath()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (neck): FPNIdentity(\n",
      "    (fpn_norms): ModuleList(\n",
      "      (0): LayerNorm()\n",
      "      (1): LayerNorm()\n",
      "      (2): LayerNorm()\n",
      "      (3): LayerNorm()\n",
      "      (4): LayerNorm()\n",
      "      (5): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (point_generator): PointGenerator(\n",
      "    (buffer_points): BufferList()\n",
      "  )\n",
      "  (cls_head): PtTransformerClsHead(\n",
      "    (act): ReLU()\n",
      "    (head): ModuleList(\n",
      "      (0): MaskedConv1D(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      )\n",
      "      (1): MaskedConv1D(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): ModuleList(\n",
      "      (0): LayerNorm()\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (cls_head): MaskedConv1D(\n",
      "      (conv): Conv1d(512, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    )\n",
      "  )\n",
      "  (reg_head): PtTransformerRegHead(\n",
      "    (act): ReLU()\n",
      "    (head): ModuleList(\n",
      "      (0): MaskedConv1D(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      )\n",
      "      (1): MaskedConv1D(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): ModuleList(\n",
      "      (0): LayerNorm()\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "    (scale): ModuleList(\n",
      "      (0): Scale()\n",
      "      (1): Scale()\n",
      "      (2): Scale()\n",
      "      (3): Scale()\n",
      "      (4): Scale()\n",
      "      (5): Scale()\n",
      "    )\n",
      "    (offset_head): MaskedConv1D(\n",
      "      (conv): Conv1d(512, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    )\n",
      "  )\n",
      "  (audio_embedder): ProjectionHeadAudio(\n",
      "    (conv1): Conv1d(1025, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (transormer_encoder): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (projection): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (gelu): GELU(approximate='none')\n",
      "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "from torchviz import make_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list =  [\n",
    "        {\n",
    "            'video_id': 'video_validation_0000155',\n",
    "            'feats': torch.rand((2048, 10)),  # Random tensor of size C x T\n",
    "            'segments': torch.tensor([[265.0, 337.0]]),\n",
    "            'labels': torch.tensor([3]),\n",
    "            'fps': 30.0,\n",
    "            'prompt': 'CleanAndJerk',\n",
    "            'audio_track': torch.rand((128, 10), dtype=torch.float64),  # Random tensor of size A x T (audio track)\n",
    "            'duration': 75.54,\n",
    "            'active_label': 3,\n",
    "            'feat_stride': 4,\n",
    "            'feat_num_frames': 16\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karolwojtulewicz/miniconda3/envs/aformer/lib/python3.10/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y = model([val_dataset[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PtTransformer' object has no attribute 'named_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m make_dot(y, params\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mnamed_params())\u001b[39m.\u001b[39mrender(\u001b[39m\"\u001b[39m\u001b[39mrnn_torchviz\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PtTransformer' object has no attribute 'named_params'"
     ]
    }
   ],
   "source": [
    "make_dot(y, params=model.named_params()).render(\"rnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
